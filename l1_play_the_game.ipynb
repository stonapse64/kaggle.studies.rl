{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17592,"databundleVersionId":899221,"sourceType":"competition"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\n**[Connect Four](https://en.wikipedia.org/wiki/Connect_Four)** is a game where two players alternate turns dropping colored discs into a vertical grid. Each player uses a different color (usually red or yellow), and the objective of the game is to be the first player to get four discs in a row. \n\n<center>\n<img src=\"https://storage.googleapis.com/kaggle-media/learn/images/40B1MGc.png\"><br/>\n</center>\n\nIn this course, you will build your own intelligent agents to play the game.\n- In the first lesson, you'll learn how to set up the game environment and create your first agent.\n- The next two lessons focus on traditional methods for building game AI.  These agents will be smart enough to defeat many novice players!\n- In the final lesson, you'll experiment with cutting-edge algorithms from the field of reinforcement learning.  The agents that you build will come up with gameplay strategies much like humans do: gradually, and with experience. \n\n# Join the competition\n\nThroughout the course, you'll test your agents' performance by competing against agents that other users have created.  \n\nTo join the competition, open a new window with **[the competition page](https://www.kaggle.com/c/connectx/overview)**, and click on the **\"Join Competition\"** button. (_If you see a \"Submit Agent\" button instead of a \"Join Competition\" button, you have already joined the competition, and don't need to do so again._)\n\n<center>\n<img src=\"https://storage.googleapis.com/kaggle-media/learn/images/dDX1YVW.png\" width=80%><br/>\n</center>\n    \nThis takes you to the rules acceptance page. You must accept the competition rules in order to participate. These rules govern how many submissions you can make per day, the maximum team size, and other competition-specific details. Then, click on **\"I Understand and Accept\"** to indicate that you will abide by the competition rules.\n\n# Getting started\n\nThe game environment comes equipped with agents that have already been implemented for you.  To see a list of these default agents, run:","metadata":{}},{"cell_type":"code","source":"from kaggle_environments import make, evaluate\n\n# Create the game environment\n# Set debug=True to see the errors if your agent refuses to run\nenv = make(\"connectx\", debug=True)\n\n# List of available default agents\nprint(list(env.agents))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:54:28.103202Z","iopub.execute_input":"2024-12-25T08:54:28.103592Z","iopub.status.idle":"2024-12-25T08:54:28.155714Z","shell.execute_reply.started":"2024-12-25T08:54:28.103557Z","shell.execute_reply":"2024-12-25T08:54:28.154367Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The `\"random\"` agent selects (uniformly) at random from the set of **valid moves**.  In Connect Four, a move is considered valid if there's still space in the column to place a disc (i.e., if the board has seven rows, the column has fewer than seven discs).\n\nIn the code cell below, this agent plays one game round against a copy of itself.","metadata":{}},{"cell_type":"code","source":"# Two random agents play one game round\nenv.run([\"random\", \"random\"])\n\n# AS: added code line to testing agent types\n# env.run([\"negamax\", \"negamax\"])\n# env.run([\"random\", \"negamax\"])\n\n# Show the game\nenv.render(mode=\"ipython\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T09:04:33.210484Z","iopub.execute_input":"2024-12-25T09:04:33.210939Z","iopub.status.idle":"2024-12-25T09:04:35.683595Z","shell.execute_reply.started":"2024-12-25T09:04:33.210908Z","shell.execute_reply":"2024-12-25T09:04:35.682125Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"You can use the player above to view the game in detail: every move is captured and can be replayed.  _Try this now!_\n\nAs you'll soon see, this information will prove incredibly useful for brainstorming ways to improve our agents.\n\n# Defining agents\n\nTo participate in the competition, you'll create your own agents.  \n\nYour agent should be implemented as a Python function that accepts two arguments: `obs` and `config`.  It returns an integer with the selected column, where indexing starts at zero.  So, the returned value is one of 0-6, inclusive.\n\nWe'll start with a few examples, to provide some context.  In the code cell below:\n- The first agent behaves identically to the `\"random\"` agent above.\n- The second agent always selects the middle column, whether it's valid or not!  Note that if any agent selects an invalid move, it loses the game.\n- The third agent selects the leftmost valid column.","metadata":{}},{"cell_type":"code","source":"\nimport random\nimport numpy as np","metadata":{"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Selects random valid column\ndef agent_random(obs, config):\n    valid_moves = [col for col in range(config.columns) if obs.board[col] == 0]\n    return random.choice(valid_moves)\n\n# Selects middle column\ndef agent_middle(obs, config):\n    return config.columns//2\n\n# Selects leftmost valid column\ndef agent_leftmost(obs, config):\n    valid_moves = [col for col in range(config.columns) if obs.board[col] == 0]\n    return valid_moves[0]","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"So, what are `obs` and `config`, exactly?\n\n### `obs`\n\n`obs` contains two pieces of information:\n- `obs.board` - the game board (a Python list with one item for each grid location)\n- `obs.mark` - the piece assigned to the agent (either `1` or `2`)\n\n`obs.board` is a Python list that shows the locations of the discs, where the first row appears first, followed by the second row, and so on. We use `1` to track player 1's discs, and `2` to track player 2's discs.  For instance, for this game board:\n\n<center>\n<img src=\"https://storage.googleapis.com/kaggle-media/learn/images/kSYx4Nx.png\" width=25%><br/>\n</center>\n\n`obs.board` would be `[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 2, 1, 2, 0, 2, 0]`.\n\n### `config` \n\n`config` contains three pieces of information:\n- `config.columns` - number of columns in the game board (`7` for Connect Four)\n- `config.rows` - number of rows in the game board (`6` for Connect Four)\n- `config.inarow` - number of pieces a player needs to get in a row in order to win (`4` for Connect Four)\n\nTake the time now to investigate the three agents we've defined above.  Make sure that the code makes sense to you!\n\n# Evaluating agents\n\nTo have the custom agents play one game round, we use the same `env.run()` method as before.","metadata":{}},{"cell_type":"code","source":"# Agents play one game round\nenv.run([agent_leftmost, agent_random])\n\n# Show the game\nenv.render(mode=\"ipython\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The outcome of a single game is usually not enough information to figure out how well our agents are likely to perform.  To get a better idea, we'll calculate the win percentages for each agent, averaged over multiple games.  For fairness, each agent goes first half of the time.\n\nTo do this, we'll use the `get_win_percentages()` function (defined in a hidden code cell).  _To view the details of this function, click on the \"Code\" button below._","metadata":{}},{"cell_type":"code","source":"\ndef get_win_percentages(agent1, agent2, n_rounds=100):\n    # Use default Connect Four setup\n    config = {'rows': 6, 'columns': 7, 'inarow': 4}\n    # Agent 1 goes first (roughly) half the time          \n    outcomes = evaluate(\"connectx\", [agent1, agent2], config, [], n_rounds//2)\n    # Agent 2 goes first (roughly) half the time      \n    outcomes += [[b,a] for [a,b] in evaluate(\"connectx\", [agent2, agent1], config, [], n_rounds-n_rounds//2)]\n    print(\"Agent 1 Win Percentage:\", np.round(outcomes.count([1,-1])/len(outcomes), 2))\n    print(\"Agent 2 Win Percentage:\", np.round(outcomes.count([-1,1])/len(outcomes), 2))\n    print(\"Number of Invalid Plays by Agent 1:\", outcomes.count([None, 0]))\n    print(\"Number of Invalid Plays by Agent 2:\", outcomes.count([0, None]))","metadata":{"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Which agent do you think performs better against the random agent: the agent that always plays in the middle (`agent_middle`), or the agent that chooses the leftmost valid column (`agent_leftmost`)?  Let's find out!","metadata":{}},{"cell_type":"code","source":"get_win_percentages(agent1=agent_middle, agent2=agent_random)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"get_win_percentages(agent1=agent_leftmost, agent2=agent_random)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"It looks like the agent that chooses the leftmost valid column performs best!\n\n# Your turn\n\nThese agents are quite simple.  As the course progresses, you'll create increasingly complex agents!  Continue to **[make your first competition submission](https://www.kaggle.com/kernels/fork/7677818)**.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-game-ai-and-reinforcement-learning/discussion) to chat with other learners.*","metadata":{}}]}