{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "[Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = A2C(\"MlpPolicy\", env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 21.7         |\n",
      "|    ep_rew_mean        | 21.7         |\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -0.693       |\n",
      "|    explained_variance | -0.016250014 |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | 1.88         |\n",
      "|    value_loss         | 9.15         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 27.1        |\n",
      "|    ep_rew_mean        | 27.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 111         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 8           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -0.688      |\n",
      "|    explained_variance | -0.03626871 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | 1.67        |\n",
      "|    value_loss         | 7.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 28.5        |\n",
      "|    ep_rew_mean        | 28.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 109         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -0.671      |\n",
      "|    explained_variance | 0.002117753 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | 1.45        |\n",
      "|    value_loss         | 6.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 33          |\n",
      "|    ep_rew_mean        | 33          |\n",
      "| time/                 |             |\n",
      "|    fps                | 108         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -0.681      |\n",
      "|    explained_variance | -0.00306952 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | 1.35        |\n",
      "|    value_loss         | 6           |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 38           |\n",
      "|    ep_rew_mean        | 38           |\n",
      "| time/                 |              |\n",
      "|    fps                | 109          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -0.618       |\n",
      "|    explained_variance | 0.0030984879 |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 1            |\n",
      "|    value_loss         | 5.3          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 42           |\n",
      "|    ep_rew_mean        | 42           |\n",
      "| time/                 |              |\n",
      "|    fps                | 108          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -0.583       |\n",
      "|    explained_variance | -0.008122325 |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | 1.42         |\n",
      "|    value_loss         | 4.63         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 48          |\n",
      "|    ep_rew_mean        | 48          |\n",
      "| time/                 |             |\n",
      "|    fps                | 108         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 32          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -0.602      |\n",
      "|    explained_variance | 0.004804313 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 0.666       |\n",
      "|    value_loss         | 4.04        |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 52.7          |\n",
      "|    ep_rew_mean        | 52.7          |\n",
      "| time/                 |               |\n",
      "|    fps                | 108           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 36            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -0.531        |\n",
      "|    explained_variance | 0.00026214123 |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | 0.866         |\n",
      "|    value_loss         | 3.54          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 55.8         |\n",
      "|    ep_rew_mean        | 55.8         |\n",
      "| time/                 |              |\n",
      "|    fps                | 108          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 41           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -0.596       |\n",
      "|    explained_variance | 0.0006301403 |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.617        |\n",
      "|    value_loss         | 3.03         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 60            |\n",
      "|    ep_rew_mean        | 60            |\n",
      "| time/                 |               |\n",
      "|    fps                | 108           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 46            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -0.567        |\n",
      "|    explained_variance | 0.00083106756 |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | 0.766         |\n",
      "|    value_loss         | 2.57          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 64.5          |\n",
      "|    ep_rew_mean        | 64.5          |\n",
      "| time/                 |               |\n",
      "|    fps                | 107           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 50            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -0.445        |\n",
      "|    explained_variance | 5.5611134e-05 |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | 0.775         |\n",
      "|    value_loss         | 2.13          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 68            |\n",
      "|    ep_rew_mean        | 68            |\n",
      "| time/                 |               |\n",
      "|    fps                | 109           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 54            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -0.55         |\n",
      "|    explained_variance | 0.00011253357 |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | 0.422         |\n",
      "|    value_loss         | 1.75          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 70.7          |\n",
      "|    ep_rew_mean        | 70.7          |\n",
      "| time/                 |               |\n",
      "|    fps                | 109           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 59            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -0.584        |\n",
      "|    explained_variance | 3.0040741e-05 |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | 0.628         |\n",
      "|    value_loss         | 1.4           |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 73.5         |\n",
      "|    ep_rew_mean        | 73.5         |\n",
      "| time/                 |              |\n",
      "|    fps                | 109          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -0.5         |\n",
      "|    explained_variance | 4.887581e-06 |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.632        |\n",
      "|    value_loss         | 1.1          |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 75.6          |\n",
      "|    ep_rew_mean        | 75.6          |\n",
      "| time/                 |               |\n",
      "|    fps                | 109           |\n",
      "|    iterations         | 1500          |\n",
      "|    time_elapsed       | 68            |\n",
      "|    total_timesteps    | 7500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -0.54         |\n",
      "|    explained_variance | -1.680851e-05 |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1499          |\n",
      "|    policy_loss        | 0.462         |\n",
      "|    value_loss         | 0.83          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 78.7         |\n",
      "|    ep_rew_mean        | 78.7         |\n",
      "| time/                 |              |\n",
      "|    fps                | 109          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 73           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -0.442       |\n",
      "|    explained_variance | 9.316206e-05 |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.443        |\n",
      "|    value_loss         | 0.589        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 83.6           |\n",
      "|    ep_rew_mean        | 83.6           |\n",
      "| time/                 |                |\n",
      "|    fps                | 109            |\n",
      "|    iterations         | 1700           |\n",
      "|    time_elapsed       | 77             |\n",
      "|    total_timesteps    | 8500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -0.474         |\n",
      "|    explained_variance | -3.2901764e-05 |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1699           |\n",
      "|    policy_loss        | 0.21           |\n",
      "|    value_loss         | 0.383          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 87.5           |\n",
      "|    ep_rew_mean        | 87.5           |\n",
      "| time/                 |                |\n",
      "|    fps                | 109            |\n",
      "|    iterations         | 1800           |\n",
      "|    time_elapsed       | 82             |\n",
      "|    total_timesteps    | 9000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -0.359         |\n",
      "|    explained_variance | -1.0848045e-05 |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1799           |\n",
      "|    policy_loss        | 0.319          |\n",
      "|    value_loss         | 0.227          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 91.3           |\n",
      "|    ep_rew_mean        | 91.3           |\n",
      "| time/                 |                |\n",
      "|    fps                | 109            |\n",
      "|    iterations         | 1900           |\n",
      "|    time_elapsed       | 87             |\n",
      "|    total_timesteps    | 9500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -0.469         |\n",
      "|    explained_variance | -4.6491623e-05 |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1899           |\n",
      "|    policy_loss        | 0.2            |\n",
      "|    value_loss         | 0.11           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 97.2          |\n",
      "|    ep_rew_mean        | 97.2          |\n",
      "| time/                 |               |\n",
      "|    fps                | 108           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 91            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -0.483        |\n",
      "|    explained_variance | -5.364418e-05 |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | 0.0766        |\n",
      "|    value_loss         | 0.0368        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x7fd40df4fcb0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a snapshot after training\n",
    "model.save(\"cart_pole_1e4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean reward is 500.0 with a standard deviation of 0.0\n"
     ]
    }
   ],
   "source": [
    "# load and evaluate a formerly saved snapshot\n",
    "model = A2C.load(\"cart_pole_1e5\", env=env)\n",
    "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
    "print(f\"The mean reward is {mean_reward} with a standard deviation of {std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Total reward in episode 1 was 500\n",
      "Total reward in episode 2 was 500\n",
      "Total reward in episode 3 was 500\n"
     ]
    }
   ],
   "source": [
    "# load a formerly saved snapshot and render animations from it\n",
    "model = A2C.load(\"cart_pole_1e5\", env=env)\n",
    "\n",
    "vec_env = model.get_env()\n",
    "obs = vec_env.reset()\n",
    "\n",
    "episodes = 3\n",
    "total_reward_episode = 0\n",
    "\n",
    "for episode in range(episodes):\n",
    "    # VecEnv resets automatically but one could optionally reset it here\n",
    "    # obs = vec_env.reset()\n",
    "    done = False    \n",
    "    total_reward_episode = 0\n",
    "    while not done:\n",
    "        action, _state = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = vec_env.step(action)\n",
    "        vec_env.render(\"human\")\n",
    "        total_reward_episode += 1\n",
    "\n",
    "    print(f\"Total reward in episode {episode + 1} was {total_reward_episode}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    }
   ],
   "source": [
    "print(1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
